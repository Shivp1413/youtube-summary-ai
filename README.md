title: Youtube Summary Ai
emoji: ğŸ¥
colorFrom: pink
colorTo: red
sdk: streamlit
sdk_version: 1.42.0
app_file: app.py
pinned: false

# YouTube Summary AI

Transform YouTube videos into concise notes and summaries using fully local AI processing. This application runs entirely on your machine with no external API calls, ensuring complete privacy and security of your data.

![Demo](assets/demo.gif)

## Key Features

- ğŸ”’ **100% Local Processing**: All AI operations run on your machine
  - No API keys required
  - No data sent to external servers
  - Complete privacy and security
  - Use CPU or GPU to run the AI
- ğŸ¯ **Offline Capable**: Once models are downloaded, works without internet
- âš¡ **Fast Processing**: Direct local inference without API latency
- ğŸ¥ Easy YouTube video URL input
- ğŸ”Š Advanced audio extraction using yt-dlp
- ğŸ“ Local transcription using Whisper
- ğŸ¤– Local AI summarization using LLaMA, Gemma or others LLM 
- ğŸŒ Shareable summary links
- ğŸ’» Clean and intuitive user interface

## How It Works

1. **Download**: Downloads YouTube video audio locally using yt-dlp
2. **Transcribe**: Processes audio using local Whisper model
3. **Summarize**: Generates summary using local LLaMA model
4. **All data stays on your machine!**

## Prerequisites

Before running the application, make sure you have the following installed:
- Python 3.8 or higher
- FFmpeg
- Ollama with LLaMA model

## Installation

1. Clone the repository
```bash
git clone https://github.com/Shivp1413/youtube-summary-ai.git
cd youtube-summary-ai
```

2. Create a virtual environment (recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```

3. Install the required packages
```bash
pip install -r requirements.txt
```

4. Install and run Ollama with LLaMA model
```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.1
```

## First-Time Setup

When you first run the application, it will:
1. Download the Whisper base model (~150MB) for local transcription
2. Use your local LLaMA model for summarization
3. All subsequent runs will use these local models

## Usage

1. Start the Streamlit application:
```bash
streamlit run app.py
```

2. Open your web browser and navigate to `http://localhost:8501`

3. Enter a YouTube URL and click "Generate Summary"

4. Share the summary using the generated link

## Project Structure

```
youtube-summary-ai/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ summarizer.py       # Video processing and local AI logic
â”œâ”€â”€ requirements.txt    # Project dependencies
â”œâ”€â”€ assets/            # Project assets
â”‚   â””â”€â”€ demo.gif       # Application demo
â””â”€â”€ README.md          # Project documentation
```

## Security Features

- âœ… No API keys needed
- âœ… No cloud services required
- âœ… All processing happens locally
- âœ… No data leaves your machine
- âœ… Full control over your data
- âœ… Works offline after initial setup

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request. 

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
